# Microsoft-Malware-prediction

## About

This is just a simple and small research kind of work which will helps you to build an AI model to predict the probability of your windows machine getting infected by a malware. The dataset for this work have been taken from [kaggle](https://www.kaggle.com/c/microsoft-malware-prediction/data) , Which contains millions of records of windows machine and their status of being affected by a malware. The dataset contains total of 84 features from which  I have used only 15 features and only 1 lakh data, due to less RAM, for training the model and i got a accuracy of approx 60% in the end. I will briefly explain the my code in the **The Code** Section.

## Features

There total of 84 features but i have used only following 15 features.
```
ProductName -  Defender state information e.g. win8defender

EngineVersion -  Defender state information e.g. 1.1.12603.0

DefaultBrowsersIdentifier -  ID for the machine's default browser  

CountryIdentifier -  ID for the country the machine is located in            

Platform -  Calculates platform name (of OS related properties and processor property)                     

Processor - This is the process architecture of the installed operating system                     

OsVer -  Version of the current operating system                         

IsProtected - This is a calculated field derived from the Spynet Report's AV Products field. Returns: a. TRUE if there is at least one active and up-to-date antivirus product 
running on this machine. b. FALSE if there is no active AV product on this machine, or if the AV is active, but is not receiving the latest updates. c. null if there are no Anti Virus Products in the report. Returns: Whether a machine is protected.                  

Firewall - This attribute is true (1) for Windows 8.1 and above if windows firewall is enabled, as reported by the service.                     

UacLuaenable  -  This attribute reports whether or not the "administrator in Admin Approval Mode" user type is disabled or enabled in UAC. The value reported is obtained by reading the regkey HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\EnableLUA

Census_IsVirtualDevice -  Identifies a Virtual Machine (machine learning model)        

Census_IsTouchEnabled - Is this a touch device ?        

Census_IsPenCapable  -  Is the device capable of pen input ?         

Wdft_IsGamer - Indicates whether the device is a gamer device or not based on its hardware combination.                 

HasDetections -  HasDetections is the ground truth and indicates that Malware was detected on the machine.                
```


## Instructions

1. Download the dataset from kaggle , link provided in about section.
2. Upload it Your Google Drive , as i will be using Google Colab for this purpose.
3. I will try to provide all the reference link used in building this model.
4. If you are just reading this code , I will recommend to open the code notebook side-by-side, this will give you a better understanding. 
5. I have written down this research work very briefly and short , so it is recommended to read the blogs given in the reference link.
6. The notebook is little messed up , because it contains the things which are not important but they helps to visualize and understand the data much better. 
7. There are also better and best codes available on the kaggle , you can refer them also.

## The Code

The model Training contains the following process:

1. *Connecting TO Google Drive*
2. *Memory Management*
3. *Removing Null values and outliers from the dataset*
4. *Finding Co-relation between the features.*
5. *Algorithm Selection*
6. *Label Encoding*
7. *Splitting the dataset for tarining and testing purpose*
8. *Training and Testing the Model*
9. *Checking the accuracy of the model.*

**Connecting To The Google Drive**

```
from google.colab import drive
drive.mount('/content/gdrive')   
```
Above code will connect will googel drive , sign in with your account give the authorization code and drive will be mounted. Now you can read your dataset by using the pandas library.

**Memory Management**

| Number of bits   |   Min. Value     |   Max Value     |
|------------------|------------------|-----------------|
| 8 bit            |     -128         |    127          |
| 16 bit           |     –32768       |    32767        |
| 32 bit           |     -2147483648  |    2147483647   |
| 64 bit           |     –2^63        |    2^63 - 1     |

For effecient memory management , we first print out the maximum and minimum value of non-object features, and from there we conclude that ehich subtypes can be used for a particular feature. For example the maximum and minimum value of *HasDetection* is 1 and 0 , so instead of using int64 we can use int16 for this feature.We finally used below code for this reducing memory and cut down the memory from 13 MB to 7 Mb, approximately 50 percent. 

```
read_file=pd.read_csv('/content/gdrive/My Drive/train.csv',usecols=["Census_IsVirtualDevice","Processor","MachineIdentifier","ProductName","EngineVersion","DefaultBrowsersIdentifier","CountryIdentifier","OsVer","IsProtected","Wdft_IsGamer", "Firewall","UacLuaenable","Census_IsTouchEnabled", "Census_IsPenCapable","HasDetections","Platform"],nrows=100000,dtype={"DefaultBrowsersIdentifier":np.float16,"CountryIdentifier":np.int16,"IsProtected":np.float16,"Wdft_IsGamer":np.float16, "Firewall":np.float16,"UacLuaenable":np.float16,"Census_IsTouchEnabled":np.int16, "Census_IsPenCapable":np.int16,"HasDetections":np.int16,"Census_IsVirtualDevice":np.float16})
```


**Removing Null values and Outliers from the dataset**

We observe in the dataset that the feature *DefaultBrowserIdentidentifier* have the most number of null values, so I decided to remove that features and also remove the rows containinig null values in other features.

```
(read_file.isnull().sum(axis=0))/1000

```

**Finding Co-relation between the features.**

Finding co-relation between the variables is important because if two features are highly co-related then we can drop one of the features. I found the co-relation between the variables by using phik module which draw a matrix showing co-relation between the variables. I found that the OsVer and Platform are highly co-related , so i drop one of the features.

```
from phik import resources,report
phik=malware_df.phik_matrix()
from phik.report import plot_correlation_matrix
import matplotlib.pyplot as plt

plot_correlation_matrix(phik.values, x_labels=phik.columns, y_labels=phik.index, 
                        vmin=0, vmax=1, color_map='Blues', title=r'correlation $\phi_K$', fontsize_factor=1.5,
                        figsize=(12,10))
plt.tight_layout()

```

**Selecting Algorithm for the Model**

For now , I have only used the LightBgm Algorithm , because it is faster thany any of the algorithms. It is one of the gradient boosting algorithms developed by microsoft , open sourced in 2017. For more information on this Algorithm , go to the reference section.

**Label Encoding**

Label Encoding is a process of converting the labels into the numeric form.For example , suppose your dataset contain a feature called "Gender" and it have values like "Male and "Female" , so the label encoding will set the values like 0 for male and 1 for female, this will helps the machine to easily understand.

```
categorical_feature_mask = malware_df.dtypes==object
# filter categorical columns using mask and turn it into a list
categorical_cols = malware_df.columns[categorical_feature_mask].tolist()
from sklearn.preprocessing import LabelEncoder
# instantiate labelencoder object
le = LabelEncoder()
malware_df[categorical_cols] = malware_df[categorical_cols].apply(lambda col: le.fit_transform(col))
malware_df[categorical_cols].head(10)
```

**Splitting the dataset for tarining and testing purpose**

I splitted the dataset for training and testing purpose. I have used 70% of data for training and rest 30% for testing.  You can use train_test_split from scikit learn library.

```
from sklearn.model_selection import train_test_split
y=malware_df['HasDetections']
malware_df=malware_df.drop(['HasDetections'],axis=1)
X_train,X_test,Y_train,Y_test=train_test_split(malware_df,y,test_size=0.4,random_state=42)
```

**Training the model**
 
I trained the model with lightgbm algorithm.
```
import lightgbm as lgb
train_s=lgb.Dataset(X_train,label=Y_train)
param={}
param['objective']='binary'
param['max_depth']=10
param['num_leaves']=700
param['min_data_in_leaf']=90
param['learning_rate']=0.1
param['metric']='auc'

training=lgb.train(param,train_s)
```
**Testing and checking the accuracy of the model**

```
from sklearn.metrics import roc_auc_score
## checking accuracy through auc
prediction = training.predict(X_test)
val_score = roc_auc_score(Y_test,prediction)
print('Validation AUC Score {}'.format(val_score))
```
In the end I got a AUC score of approx 0.60 , which means my model predicting accuracy is 60%. You can also use the pickle for saving the training model and use it later for prediction, so that you don't need to trin your model every time.  

Thats How i build my AI model.

## References
1. https://medium.com/swlh/microsoft-malware-prediction-using-classical-machine-learning-algorithms-5ade962ca73a
2. https://www.kaggle.com/c/microsoft-malware-prediction
3. https://www.dataquest.io/blog/pandas-big-data/
4. https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba
5. https://towardsdatascience.com/what-it-takes-to-be-correlated-ce41ad0d8d7f
6. https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc
7. https://lightgbm.readthedocs.io/en/latest/

## Future Work

1. Increasing the accuracy by trying other algorithms.
2. Implementation of this project for real world usage.

## Creator
Twitter: [Divyanshu Diwakar](https://twitter.com/ddiwakr)




